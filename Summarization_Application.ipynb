{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a649ca2",
   "metadata": {},
   "source": [
    "# Project-1:Summarization Application using Langchain and openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cda2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61010f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ee568",
   "metadata": {},
   "source": [
    "## A) Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54691197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2006299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.\n",
    "Mojo is a new programming language that bridges the gap between research and production by combining the best of Python syntax with systems programming and metaprogramming.\n",
    "With Mojo, you can write portable code that’s faster than C and seamlessly inter-op with the Python ecosystem.\n",
    "When we started Modular, we had no intention of building a new programming language. But as we were building our platform \n",
    "with the intent to unify the world’s ML/AI infrastructure, we realized that programming across the entire stack was too \n",
    "complicated. Plus, we were writing a lot of MLIR by hand and not having a good time.\n",
    "And although accelerators are important, one of the most prevalent and sometimes overlooked “accelerators” is the host CPU.\n",
    "Nowadays, CPUs have lots of tensor-core-like accelerator blocks and other AI acceleration units, but they also serve as the \n",
    "“fallback” for operations that specialized accelerators don’t handle, such as data loading, pre- and post-processing, and\n",
    "integrations with foreign systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7e31ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    SystemMessage(content='You are an expert copywriter with expertize in summarizing document'),\n",
    "    HumanMessage(content=f'Please provide a short and concise summary of the fillowing text:\\n TEXT:y {text}')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6ce3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77344297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "775bb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_output=llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f16ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
